# Get all distinct series and order by release_date ascending
SELECT DISTINCT
  (data->'set'->>'series') AS series,
  MIN(TO_DATE(data->'set'->>'releaseDate', 'YYYY/MM/DD')) AS earliest_release
FROM "Card"
WHERE data->'set'->>'series' IS NOT NULL
GROUP BY series
ORDER BY earliest_release ASC;


# Get all distinct sets and order by release_date ascending
SELECT DISTINCT 
  data->'set'->>'id' AS set_id,
  data->'set'->>'name' AS set_name,
  data->'set'->>'releaseDate' AS release_date
FROM "Card"
WHERE data->'set' IS NOT NULL
ORDER BY data->'set'->>'releaseDate' ASC;

# Get all sets in a series and order by release_date ascending
SELECT DISTINCT
  c.data->'set'->>'id' AS set_id,
  c.data->'set'->>'name' AS set_name,
  c.data->'set'->>'releaseDate' AS release_date
FROM "Card" c
WHERE c.data->'set'->>'series' = 'YOUR_SERIES_NAME'
ORDER BY TO_DATE(c.data->'set'->>'releaseDate', 'YYYY/MM/DD') ASC;

# Postgres fuzzy search
CREATE EXTENSION IF NOT EXISTS pg_trgm;
CREATE INDEX idx_card_name_trgm ON "Card" USING gin ((data->>'name') gin_trgm_ops);

SELECT *
FROM "Card"
WHERE (data->>'name') % $1
ORDER BY similarity((data->>'name'), $1) DESC
LIMIT 10

# indexes for getting top movers per set
CREATE EXTENSION IF NOT EXISTS pg_trgm;
CREATE INDEX idx_card_name_trgm ON "Card" USING gin ((data->>'name') gin_trgm_ops);
 -- Filter and join efficiency
CREATE INDEX IF NOT EXISTS idx_priceentry_cardid_date ON "PriceEntry"("cardId", "date");

-- For JSONB series filtering
CREATE INDEX IF NOT EXISTS idx_card_series ON "Card" ((data->'set'->>'series'));


# removing outliers (for eBay data)
To remove rows with outlier price values from your SealedPriceEntry table, you need to define what qualifies as an outlier. A common statistical method is to use the Interquartile Range (IQR) or Z-score.

Here’s how to do it using IQR in SQL (assuming you're using PostgreSQL):

✅ Option 1: Use IQR to detect and delete outliers
WITH price_stats AS (
  SELECT
    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY price) AS q1,
    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY price) AS q3
  FROM "SealedPriceEntry"
),
outliers AS (
  SELECT spe.*
  FROM "SealedPriceEntry" spe, price_stats
  WHERE spe.price < (q1 - 1.5 * (q3 - q1))
     OR spe.price > (q3 + 1.5 * (q3 - q1))
)
DELETE FROM "SealedPriceEntry"
WHERE id IN (SELECT id FROM outliers);

✅ Option 2: Use Z-score (e.g., remove rows with z-score > 3 or < -3)
This is more appropriate if your data is normally distributed:

WITH stats AS (
  SELECT
    AVG(price) AS mean,
    STDDEV(price) AS stddev
  FROM "SealedPriceEntry"
),
outliers AS (
  SELECT spe.*
  FROM "SealedPriceEntry" spe, stats
  WHERE ABS(price - mean) / NULLIF(stddev, 0) > 3
)
DELETE FROM "SealedPriceEntry"
WHERE id IN (SELECT id FROM outliers);

# backing up DB
-note: docker compose has the volume name as 'pgdata'. Docker Compose appends the volume name to the directory
 the docker-compose.yml file is, in this case it was 'pokegraph' hence the name 'pokegraph_pgdata'
docker run --rm \
  -v pokegraph_pgdata:/volume \
  -v "$(pwd)":/backup \
  alpine sh -c "tar czf /backup/pokegraph_pgdata-backup.tar.gz -C /volume ."

-- other way I backed up the db
-- This backs up all data without schema definitions, which avoids Prisma drift issues.
docker exec -t pokedb pg_dump -U postgres --data-only pokedex > pokedex-data.sql

-- reset db (I was forced to do this)
npx prisma migrate reset

-- restore from backup
cat pokedex-data.sql | docker exec -i pokedb psql -U postgres -d pokedex

-- test



docker exec -t pokedb pg_dump -U postgres -d postgres > backup.sql